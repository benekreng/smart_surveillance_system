{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a484d10-971a-44bf-9076-ece69c66c6c2",
   "metadata": {},
   "source": [
    "# Multiple of 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "915c126c-327f-44ee-9ba1-fba9ed681997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  0 ________ Y:  0\n",
      "X:  32 ________ Y:  24\n",
      "X:  64 ________ Y:  48\n",
      "X:  96 ________ Y:  72\n",
      "X:  128 ________ Y:  96\n",
      "X:  160 ________ Y:  120\n",
      "X:  192 ________ Y:  144\n",
      "X:  224 ________ Y:  168\n",
      "X:  256 ________ Y:  192\n",
      "X:  288 ________ Y:  216\n",
      "X:  320 ________ Y:  240\n",
      "X:  352 ________ Y:  264\n",
      "X:  384 ________ Y:  288\n",
      "X:  416 ________ Y:  312\n",
      "X:  448 ________ Y:  336\n",
      "X:  480 ________ Y:  360\n",
      "X:  512 ________ Y:  384\n",
      "X:  544 ________ Y:  408\n",
      "X:  576 ________ Y:  432\n",
      "X:  608 ________ Y:  456\n",
      "X:  640 ________ Y:  480\n",
      "X:  672 ________ Y:  504\n",
      "X:  704 ________ Y:  528\n",
      "X:  736 ________ Y:  552\n",
      "X:  768 ________ Y:  576\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    x = 32 * i\n",
    "    y = x * 3/4\n",
    "    print(\"X: \", x,  \"_\" * 8, \"Y: \", int(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8610b9-fa76-4af5-83c6-12a29a24a0f3",
   "metadata": {},
   "source": [
    "# Converting Yolo to ncnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b10325b-63b1-477e-8c90-45288c1007f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5.35M/5.35M [00:00<00:00, 25.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.68 🚀 Python-3.9.21 torch-2.5.1 CPU (Cortex-A76)\n",
      "YOLO11n summary (fused): 238 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 256, 256) BCHW and output shape(s) (1, 84, 1344) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.5.1...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ✅ 3.5s, saved as 'yolo11n.torchscript' (10.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m starting export with NCNN 1.0.20241226...\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m WARNING ⚠️ PNNX not found. Attempting to download binary file from https://github.com/pnnx/pnnx/.\n",
      "Note PNNX Binary file must be placed in current working directory or in /home/vesper_pi/miniconda3/envs/surveillance/lib/python3.9/site-packages/ultralytics. See PNNX repo for full installation instructions.\n",
      "\u001b[34m\u001b[1mNCNN:\u001b[0m successfully found latest PNNX asset file pnnx-20241223-linux-aarch64.zip\n",
      "Downloading https://github.com/pnnx/pnnx/releases/download/20241223/pnnx-20241223-linux-aarch64.zip to 'pnnx-20241223-linux-aarch64.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 19.9M/19.9M [00:00<00:00, 26.6MB/s]\n",
      "Unzipping pnnx-20241223-linux-aarch64.zip to /home/vesper_pi/surveillance_system/pipeline/pnnx-20241223-linux-aarch64...: 100%|██████████| 3/3 [00:00<00:00,  7.07fi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mNCNN:\u001b[0m running '/home/vesper_pi/miniconda3/envs/surveillance/lib/python3.9/site-packages/ultralytics/pnnx yolo11n.torchscript ncnnparam=yolo11n_ncnn_model/model.ncnn.param ncnnbin=yolo11n_ncnn_model/model.ncnn.bin ncnnpy=yolo11n_ncnn_model/model_ncnn.py pnnxparam=yolo11n_ncnn_model/model.pnnx.param pnnxbin=yolo11n_ncnn_model/model.pnnx.bin pnnxpy=yolo11n_ncnn_model/model_pnnx.py pnnxonnx=yolo11n_ncnn_model/model.pnnx.onnx fp16=0 device=cpu inputshape=\"[1, 3, 256, 256]\"'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "pnnxparam = yolo11n_ncnn_model/model.pnnx.param\n",
      "pnnxbin = yolo11n_ncnn_model/model.pnnx.bin\n",
      "pnnxpy = yolo11n_ncnn_model/model_pnnx.py\n",
      "pnnxonnx = yolo11n_ncnn_model/model.pnnx.onnx\n",
      "ncnnparam = yolo11n_ncnn_model/model.ncnn.param\n",
      "ncnnbin = yolo11n_ncnn_model/model.ncnn.bin\n",
      "ncnnpy = yolo11n_ncnn_model/model_ncnn.py\n",
      "fp16 = 0\n",
      "optlevel = 2\n",
      "device = cpu\n",
      "inputshape = [1,3,256,256]f32\n",
      "inputshape2 = \n",
      "customop = \n",
      "moduleop = \n",
      "get inputshape from traced inputs\n",
      "inputshape = [1,3,256,256]f32\n",
      "Error in cpuinfo: prctl(PR_SVE_GET_VL) failed\n",
      "############# pass_level0\n",
      "inline module = torch.nn.modules.linear.Identity\n",
      "inline module = ultralytics.nn.modules.block.Attention\n",
      "inline module = ultralytics.nn.modules.block.Bottleneck\n",
      "inline module = ultralytics.nn.modules.block.C2PSA\n",
      "inline module = ultralytics.nn.modules.block.C3k\n",
      "inline module = ultralytics.nn.modules.block.C3k2\n",
      "inline module = ultralytics.nn.modules.block.DFL\n",
      "inline module = ultralytics.nn.modules.block.PSABlock\n",
      "inline module = ultralytics.nn.modules.block.SPPF\n",
      "inline module = ultralytics.nn.modules.conv.Concat\n",
      "inline module = ultralytics.nn.modules.conv.Conv\n",
      "inline module = ultralytics.nn.modules.conv.DWConv\n",
      "inline module = ultralytics.nn.modules.head.Detect\n",
      "inline module = torch.nn.modules.linear.Identity\n",
      "inline module = ultralytics.nn.modules.block.Attention\n",
      "inline module = ultralytics.nn.modules.block.Bottleneck\n",
      "inline module = ultralytics.nn.modules.block.C2PSA\n",
      "inline module = ultralytics.nn.modules.block.C3k\n",
      "inline module = ultralytics.nn.modules.block.C3k2\n",
      "inline module = ultralytics.nn.modules.block.DFL\n",
      "inline module = ultralytics.nn.modules.block.PSABlock\n",
      "inline module = ultralytics.nn.modules.block.SPPF\n",
      "inline module = ultralytics.nn.modules.conv.Concat\n",
      "inline module = ultralytics.nn.modules.conv.Conv\n",
      "inline module = ultralytics.nn.modules.conv.DWConv\n",
      "inline module = ultralytics.nn.modules.head.Detect\n",
      "\n",
      "----------------\n",
      "\n",
      "############# pass_level1\n",
      "############# pass_level2\n",
      "############# pass_level3\n",
      "############# pass_level4\n",
      "############# pass_level5\n",
      "############# pass_ncnn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mNCNN:\u001b[0m export success ✅ 4.6s, saved as 'yolo11n_ncnn_model' (10.0 MB)\n",
      "\n",
      "Export complete (9.3s)\n",
      "Results saved to \u001b[1m/home/vesper_pi/surveillance_system/pipeline\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolo11n_ncnn_model imgsz=256  \n",
      "Validate:        yolo val task=detect model=yolo11n_ncnn_model imgsz=256 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolo11n_ncnn_model'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install ultralytics\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# export the model for a lower input resolution/shape 320 for performance improvement\n",
    "model.export(format=\"ncnn\", imgsz=(256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f642705-a3e0-407c-ac2f-91014d37f390",
   "metadata": {},
   "source": [
    "# Convert edgeface from pytorch to onnx. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e170f9-9760-42d5-977e-42f1af40eebc",
   "metadata": {},
   "source": [
    "### After many tries I gave up to convert it to ncnn cause it has to many layers not available in ncnn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4776de88-d962-4f8b-8d14-7a5883fa52df",
   "metadata": {},
   "source": [
    "Using pytorch (which has the model in its repository) to export model to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1958ea4d-ca97-4f37-8020-6ae524afa47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/vesper_pi0/.cache/torch/hub/otroshi_edgeface_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been exported to ONNX format at edgeface_s_gamma_05.onnx.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_name = \"edgeface_s_gamma_05\"\n",
    "model = torch.hub.load('otroshi/edgeface', model_name, source='github', pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 112, 112)\n",
    "\n",
    "onnx_file_path = f\"{model_name}.onnx\"\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_file_path,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"batch_size\"},\n",
    "        \"output\": {0: \"batch_size\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"Model has been exported to ONNX format at {onnx_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44407b50-7fa0-4435-aa37-5c7809c7b037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
